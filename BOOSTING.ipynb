{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83b7a2bd-4b1f-45bd-b172-752bf1fcb39a",
   "metadata": {},
   "source": [
    "Question 1: What is Boosting in Machine Learning? Explain how it improves weak\n",
    "learners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6967b-aa30-494c-b932-d95a2655cc9b",
   "metadata": {},
   "source": [
    "**Boosting in Machine Learning**\n",
    "Boosting is an ensemble method that combines many weak learners (like shallow decision trees) to form a strong learner.\n",
    "\n",
    "**How it works:**\n",
    "1.Train a weak learner.\n",
    "\n",
    "2.Increase weights on misclassified samples.\n",
    "\n",
    "3.Train the next learner focusing on those errors.\n",
    "\n",
    "4.Repeat the process.\n",
    "\n",
    "5.Combine all learners (weighted voting/averaging).\n",
    "\n",
    "Why it improves weak learners:\n",
    "Each new model fixes the mistakes of the previous one, so together they achieve high accuracy.\n",
    "\n",
    "Examples: AdaBoost, Gradient Boosting, XGBoost, LightGBM.\n",
    "****************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7385da6e-5669-4206-a58c-da510af08a66",
   "metadata": {},
   "source": [
    "Question 2: What is the difference between AdaBoost and Gradient Boosting in terms\n",
    "of how models are trained?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5128c12b-0173-49b6-9185-ac7009695123",
   "metadata": {},
   "source": [
    "Difference between AdaBoost and Gradient Boosting\n",
    "\n",
    "1. Training Approach\n",
    "\n",
    "**AdaBoost (Adaptive Boosting):**\n",
    "\n",
    "Learners are trained sequentially.\n",
    "\n",
    "After each round, it increases the weights of misclassified samples so that the next learner focuses more on those “hard” cases.\n",
    "\n",
    "Final prediction is a weighted majority vote (classification) or weighted sum (regression).\n",
    "\n",
    "**Gradient Boosting:**\n",
    "\n",
    "Learners are also trained sequentially, but instead of reweighting data, it uses gradient descent to minimize a chosen loss function (e.g., mean squared error, log loss).\n",
    "\n",
    "Each new model is fit on the residual errors (gradients) of the previous model.\n",
    "\n",
    "Final prediction is the sum of all learners.\n",
    "\n",
    "**2. Key Idea**\n",
    "\n",
    "AdaBoost → Emphasizes hard-to-classify points by reweighting them.\n",
    "\n",
    "Gradient Boosting → Directly optimizes errors by using gradients of the loss function.\n",
    "\n",
    "**3. Example**\n",
    "\n",
    "In AdaBoost, if a patient case is repeatedly misclassified, its weight increases so future models pay extra attention to it.\n",
    "\n",
    "In Gradient Boosting, if the model predicts a patient’s disease probability incorrectly, the next learner tries to fix the numerical difference (residual) between predicted and actual values.\n",
    "***************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8fd47d-77d5-4bb3-9f76-d99f0dedfee3",
   "metadata": {},
   "source": [
    "Question 3: How does regularization help in XGBoost?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ebb72-4f95-4407-9a51-e5f0108de2f4",
   "metadata": {},
   "source": [
    "**Regularization in XGBoost**\n",
    "\n",
    "XGBoost (Extreme Gradient Boosting) is an advanced version of gradient boosting, and one of its strengths is the use of regularization to control model complexity.\n",
    "\n",
    "**How it helps:**\n",
    "\n",
    "**Prevents Overfitting**\n",
    "\n",
    "XGBoost adds penalty terms to the objective function (both L1 and L2 regularization).\n",
    "\n",
    "This discourages the model from creating overly complex trees that perfectly fit training data but perform poorly on test data.\n",
    "\n",
    "**Controls Tree Complexity**\n",
    "\n",
    "Regularization penalizes too many leaves (deep trees) and large weights on leaf nodes.\n",
    "\n",
    "This keeps the model simpler and more generalizable.\n",
    "\n",
    "**Balances Accuracy and Simplicity**\n",
    "\n",
    "Without regularization → high variance, overfitting.\n",
    "\n",
    "With regularization → better generalization and more stable predictions\n",
    "**********"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebf3522-532d-45a2-9c8d-0df9cbde9426",
   "metadata": {},
   "source": [
    "Question 4: Why is CatBoost considered efficient for handling categorical data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c29f8ac-b299-4fe5-904d-1aa63965eedd",
   "metadata": {},
   "source": [
    "**CatBoost and Categorical Data**\n",
    "\n",
    "CatBoost (Categorical Boosting) is a gradient boosting library developed by Yandex, and it’s especially efficient for handling categorical features.\n",
    "\n",
    "**Reasons why CatBoost is efficient:**\n",
    "\n",
    "**No Need for One-Hot Encoding or Label Encoding**\n",
    "\n",
    "Most algorithms require converting categorical variables into numbers (e.g., one-hot encoding), which increases dimensionality.\n",
    "\n",
    "CatBoost handles categorical features directly, reducing preprocessing time and memory usage.\n",
    "\n",
    "**Uses \"Ordered Target Statistics\"**\n",
    "\n",
    "Instead of simple label encoding, CatBoost replaces categories with statistics (like mean target values) calculated in a way that prevents data leakage.\n",
    "\n",
    "Example: If predicting disease risk, CatBoost may replace “Gender” = Male with the average disease rate for males (computed carefully).\n",
    "\n",
    "**Efficient with High Cardinality**\n",
    "\n",
    "CatBoost works well even when categorical features have many unique values (e.g., ZIP codes, patient IDs).\n",
    "\n",
    "Traditional methods would struggle or explode in dimensionality.\n",
    "\n",
    "Faster Training and Better Accuracy**\n",
    "\n",
    "Since it avoids heavy preprocessing and encodes categories smartly, training is faster and models are often more accurate.\n",
    "*************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67b69ce7-a138-492f-a4bc-a5e44d9342f2",
   "metadata": {},
   "source": [
    "Question 4: Why is CatBoost considered efficient for handling categorical data?\n",
    "\n",
    "**Why CatBoost is Efficient for Categorical Data**\n",
    "\n",
    "CatBoost (Categorical Boosting) is designed to work directly with categorical features, unlike most boosting algorithms that require preprocessing.\n",
    "\n",
    "**Key reasons:**\n",
    "\n",
    "**1.No manual encoding needed**\n",
    "\n",
    "Normally, categorical data must be converted with one-hot encoding or label encoding, which increases dimensionality.\n",
    "\n",
    "CatBoost natively handles categorical features, saving preprocessing effort.\n",
    "\n",
    "**3. Ordered Target Statistics (OTS)**\n",
    "\n",
    "CatBoost replaces categories with values derived from the target statistics (like mean target for that category).\n",
    "\n",
    "It uses an ordered scheme to avoid data leakage, making the encoding unbiased.\n",
    "\n",
    "**4. Handles High Cardinality**\n",
    "\n",
    "Works well with features that have many unique categories (e.g., ZIP codes, product IDs, patient IDs), where one-hot encoding would be inefficient.\n",
    "\n",
    "**5. Better Accuracy & Efficiency**\n",
    "\n",
    "By encoding categories smartly, CatBoost reduces overfitting and improves training speed compared to traditional encodings.\n",
    "**************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa94a2-aa93-44ff-aa1f-3e0a7f73d87a",
   "metadata": {},
   "source": [
    "Question 5: What are some real-world applications where boosting techniques are\n",
    "preferred over bagging methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d0af7f-b457-4518-ae85-9ac216d14ddc",
   "metadata": {},
   "source": [
    "**Real-World Applications where Boosting is Preferred over Bagging**\n",
    "\n",
    "Boosting (e.g., AdaBoost, Gradient Boosting, XGBoost, CatBoost) is preferred when high accuracy and handling complex patterns are more important than just reducing variance.\n",
    "\n",
    "**Some real-world applications:**\n",
    "\n",
    "**1. Healthcare (Disease Prediction & Risk Scoring)**\n",
    "\n",
    "Boosting models (XGBoost, CatBoost) are widely used for predicting patient outcomes, disease diagnosis, and drug response because they capture subtle patterns in imbalanced data better than bagging.\n",
    "\n",
    "**2. Finance (Credit Scoring & Fraud Detection)**\n",
    "\n",
    "Boosting is preferred for detecting credit card fraud or predicting loan defaults since it focuses on hard-to-classify cases, which bagging may miss.\n",
    "\n",
    "**Marketing & Customer Analytics**\n",
    "\n",
    "In churn prediction and personalized recommendations, boosting gives better accuracy by handling categorical + numerical data efficiently.\n",
    "\n",
    "**3. Search Engines & Recommendation Systems**\n",
    "\n",
    "Companies like Google, Amazon, and Netflix use boosting (especially XGBoost and CatBoost) for ranking search results and making recommendations.\n",
    "\n",
    "**4. Competitions & High-Stakes Predictions**\n",
    "\n",
    "In Kaggle competitions and other data science challenges, boosting methods dominate because they consistently provide state-of-the-art performance.\n",
    "\n",
    "**5. Competitions & High-Stakes Predictions**\n",
    "\n",
    "In Kaggle competitions and other data science challenges, boosting methods dominate because they consistently provide state-of-the-art performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51af5906-0640-4917-acb0-2cf31173c05b",
   "metadata": {},
   "source": [
    "*************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d01cef7-472f-4e28-bddf-9106ea192a66",
   "metadata": {},
   "source": [
    "Datasets:\n",
    "● Use sklearn.datasets.load_breast_cancer() for classification tasks.\n",
    "● Use sklearn.datasets.fetch_california_housing() for regression\n",
    "tasks.\n",
    "\n",
    "Question 6: Write a Python program to:\n",
    "● Train an AdaBoost Classifier on the Breast Cancer dataset\n",
    "● Print the model accuracy|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5420a8f8-a580-42b7-8dad-c6873ee0f5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost classifier Accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "x = data.data\n",
    "y = data.target\n",
    "\n",
    "#spli the tarining and testing sets (80% train and 20% test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size = 0.2, random_state = 42\n",
    ")\n",
    "\n",
    "#initialize Adaboost classifier\n",
    "model = AdaBoostClassifier(n_estimators = 100, random_state = 42)\n",
    "\n",
    "#train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#make predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "#evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"AdaBoost classifier Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1726d24-0522-49fb-9607-fa8a9bde08f8",
   "metadata": {},
   "source": [
    "Question 7: Write a Python program to:\n",
    "● Train a Gradient Boosting Regressor on the California Housing dataset\n",
    "● Evaluate performance using R-squared score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31b2d982-1e98-4390-8d3c-03b7e4a9afb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor R squares score : 0.8004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#load the california housing dataset\n",
    "data = fetch_california_housing()\n",
    "x = data.data\n",
    "y = data.target\n",
    "\n",
    "#split into training and testing sets (80% train, 20% test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x,y, test_size = 0.2, random_state = 42\n",
    ")\n",
    "\n",
    "#initialize gradient bossting regressor\n",
    "model = GradientBoostingRegressor(n_estimators =200, learning_rate = 0.1, max_depth = 3, random_state = 42)\n",
    "\n",
    "#train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#make prediction\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "#evalaute the R Squared score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Gradient Boosting Regressor R squares score : {r2:.4f}\")\n",
    "                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b6ce13-513d-49d9-87a4-15b495121c50",
   "metadata": {},
   "source": [
    "Question 8: Write a Python program to:\n",
    "● Train an XGBoost Classifier on the Breast Cancer dataset\n",
    "● Tune the learning rate using GridSearchCV\n",
    "● Print the best parameters and accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "233cc563-2a06-40f6-8477-8dad070cf64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-3.0.4-py3-none-win_amd64.whl (56.8 MB)\n",
      "   ---------------------------------------- 0.0/56.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.0/56.8 MB 7.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.8/56.8 MB 5.0 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 2.6/56.8 MB 4.6 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 3.4/56.8 MB 4.4 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 4.2/56.8 MB 4.3 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 5.0/56.8 MB 4.2 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 5.8/56.8 MB 4.1 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 6.6/56.8 MB 4.1 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 7.3/56.8 MB 4.1 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 8.1/56.8 MB 4.1 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 8.9/56.8 MB 4.0 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 9.7/56.8 MB 4.0 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 10.7/56.8 MB 4.0 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 11.5/56.8 MB 4.0 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 12.3/56.8 MB 4.0 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 13.1/56.8 MB 4.0 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 13.9/56.8 MB 4.0 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 14.7/56.8 MB 4.0 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 15.5/56.8 MB 4.0 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 16.3/56.8 MB 4.0 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 17.0/56.8 MB 4.0 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 17.8/56.8 MB 4.0 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 18.6/56.8 MB 4.0 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 19.4/56.8 MB 4.0 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 20.2/56.8 MB 4.0 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 21.0/56.8 MB 3.9 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 21.8/56.8 MB 3.9 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 22.5/56.8 MB 3.9 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 23.3/56.8 MB 3.9 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 24.4/56.8 MB 3.9 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 25.2/56.8 MB 3.9 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 26.0/56.8 MB 3.9 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 26.7/56.8 MB 3.9 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 27.5/56.8 MB 3.9 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 28.3/56.8 MB 3.9 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 29.1/56.8 MB 3.9 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 29.9/56.8 MB 3.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 30.7/56.8 MB 3.9 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 31.5/56.8 MB 3.9 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 32.2/56.8 MB 3.9 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 33.0/56.8 MB 3.9 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 33.8/56.8 MB 3.9 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 34.6/56.8 MB 3.9 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 35.4/56.8 MB 3.9 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 36.2/56.8 MB 3.9 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 37.0/56.8 MB 3.9 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 37.7/56.8 MB 3.9 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 38.8/56.8 MB 3.9 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 39.6/56.8 MB 3.9 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 40.4/56.8 MB 3.9 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 41.2/56.8 MB 3.9 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 41.9/56.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 42.7/56.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 43.5/56.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 44.3/56.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 45.1/56.8 MB 3.9 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 45.9/56.8 MB 3.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 46.7/56.8 MB 3.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 47.7/56.8 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 48.5/56.8 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 49.3/56.8 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 50.1/56.8 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 50.9/56.8 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 51.6/56.8 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 52.4/56.8 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 53.2/56.8 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 54.0/56.8 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 54.8/56.8 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  55.6/56.8 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.4/56.8 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.6/56.8 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 56.8/56.8 MB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a147b87-2b71-4e3c-828a-d281a5d6b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.2}\n",
      "XGBoost Classifier Accuracy: 0.9561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:46:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Parameter grid for learning rate\n",
    "param_grid = {'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3]}\n",
    "\n",
    "# Grid Search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"XGBoost Classifier Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fb1cbd-b44c-4640-846d-425cb16419a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 9: Write a Python program to:\n",
    "● Train a CatBoost Classifier\n",
    "● Plot the confusion matrix using seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b7a0af76-57a5-4432-b639-55008b890348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.8-cp312-cp312-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.3)\n",
      "Downloading catboost-1.2.8-cp312-cp312-win_amd64.whl (102.4 MB)\n",
      "   ---------------------------------------- 0.0/102.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/102.4 MB 5.6 MB/s eta 0:00:19\n",
      "    --------------------------------------- 1.8/102.4 MB 5.0 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 2.6/102.4 MB 4.6 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 3.4/102.4 MB 4.4 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 4.2/102.4 MB 4.3 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 5.0/102.4 MB 4.2 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 5.5/102.4 MB 4.0 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 6.0/102.4 MB 3.8 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 6.6/102.4 MB 3.7 MB/s eta 0:00:27\n",
      "   -- ------------------------------------- 7.3/102.4 MB 3.6 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 8.1/102.4 MB 3.6 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 8.7/102.4 MB 3.5 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 9.2/102.4 MB 3.5 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 9.7/102.4 MB 3.4 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 10.2/102.4 MB 3.4 MB/s eta 0:00:28\n",
      "   ---- ----------------------------------- 11.0/102.4 MB 3.3 MB/s eta 0:00:28\n",
      "   ---- ----------------------------------- 11.8/102.4 MB 3.4 MB/s eta 0:00:28\n",
      "   ---- ----------------------------------- 12.6/102.4 MB 3.4 MB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 13.4/102.4 MB 3.4 MB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 14.2/102.4 MB 3.4 MB/s eta 0:00:26\n",
      "   ----- ---------------------------------- 14.9/102.4 MB 3.5 MB/s eta 0:00:26\n",
      "   ------ --------------------------------- 15.7/102.4 MB 3.5 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 16.5/102.4 MB 3.5 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 17.3/102.4 MB 3.5 MB/s eta 0:00:25\n",
      "   ------- -------------------------------- 18.1/102.4 MB 3.5 MB/s eta 0:00:24\n",
      "   ------- -------------------------------- 18.9/102.4 MB 3.5 MB/s eta 0:00:24\n",
      "   ------- -------------------------------- 19.7/102.4 MB 3.5 MB/s eta 0:00:24\n",
      "   ------- -------------------------------- 20.4/102.4 MB 3.6 MB/s eta 0:00:24\n",
      "   -------- ------------------------------- 21.2/102.4 MB 3.6 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 22.0/102.4 MB 3.6 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 22.5/102.4 MB 3.6 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 23.3/102.4 MB 3.5 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 23.9/102.4 MB 3.5 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 24.4/102.4 MB 3.5 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 24.9/102.4 MB 3.5 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 25.4/102.4 MB 3.4 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 26.0/102.4 MB 3.4 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 26.7/102.4 MB 3.4 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 27.3/102.4 MB 3.4 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 27.8/102.4 MB 3.4 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 28.6/102.4 MB 3.4 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 29.1/102.4 MB 3.4 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 29.6/102.4 MB 3.3 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 30.1/102.4 MB 3.3 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 30.9/102.4 MB 3.3 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 31.7/102.4 MB 3.3 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 32.5/102.4 MB 3.3 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 33.3/102.4 MB 3.4 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 34.3/102.4 MB 3.4 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 35.1/102.4 MB 3.4 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 35.9/102.4 MB 3.4 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 36.7/102.4 MB 3.4 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 37.5/102.4 MB 3.4 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 38.3/102.4 MB 3.4 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 39.1/102.4 MB 3.4 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 39.8/102.4 MB 3.4 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 40.6/102.4 MB 3.4 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 41.4/102.4 MB 3.4 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 42.2/102.4 MB 3.5 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 43.0/102.4 MB 3.5 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 43.8/102.4 MB 3.5 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 44.8/102.4 MB 3.5 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 45.6/102.4 MB 3.5 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 46.1/102.4 MB 3.5 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 47.2/102.4 MB 3.5 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 48.0/102.4 MB 3.5 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 48.8/102.4 MB 3.5 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 49.5/102.4 MB 3.5 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 50.3/102.4 MB 3.5 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 51.1/102.4 MB 3.5 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 51.9/102.4 MB 3.5 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 52.7/102.4 MB 3.5 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 53.5/102.4 MB 3.5 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 54.3/102.4 MB 3.5 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 55.1/102.4 MB 3.5 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 55.8/102.4 MB 3.5 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 56.6/102.4 MB 3.6 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 57.4/102.4 MB 3.6 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 57.9/102.4 MB 3.5 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 59.0/102.4 MB 3.6 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 59.8/102.4 MB 3.6 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 60.6/102.4 MB 3.6 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 61.3/102.4 MB 3.6 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 62.1/102.4 MB 3.6 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 62.9/102.4 MB 3.6 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 63.7/102.4 MB 3.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 64.5/102.4 MB 3.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 65.5/102.4 MB 3.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 66.3/102.4 MB 3.6 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 67.1/102.4 MB 3.6 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 67.9/102.4 MB 3.6 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 68.7/102.4 MB 3.6 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 69.5/102.4 MB 3.6 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 70.3/102.4 MB 3.6 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 71.0/102.4 MB 3.6 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 71.8/102.4 MB 3.6 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 72.6/102.4 MB 3.6 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 73.4/102.4 MB 3.6 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 74.2/102.4 MB 3.6 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 75.0/102.4 MB 3.6 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 75.8/102.4 MB 3.6 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 76.5/102.4 MB 3.6 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 77.1/102.4 MB 3.6 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 77.6/102.4 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 78.4/102.4 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 78.9/102.4 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 79.4/102.4 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 80.0/102.4 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 80.5/102.4 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 81.5/102.4 MB 3.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 82.3/102.4 MB 3.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 83.1/102.4 MB 3.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 83.9/102.4 MB 3.6 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 84.7/102.4 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 85.5/102.4 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 86.2/102.4 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 87.0/102.4 MB 3.6 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 87.8/102.4 MB 3.6 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 88.9/102.4 MB 3.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 89.7/102.4 MB 3.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 90.4/102.4 MB 3.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 91.2/102.4 MB 3.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 92.0/102.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 92.8/102.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.6/102.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 94.4/102.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.2/102.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.9/102.4 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 96.7/102.4 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 97.5/102.4 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 98.3/102.4 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 99.1/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.9/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.7/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.7/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  102.2/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  102.2/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  102.2/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 102.4/102.4 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.2.8 graphviz-0.21\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "857d5a30-c7eb-42c3-8443-1e2b41bcee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost classifier Accuracy: 0.9649\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "#load the Breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "x = data.data\n",
    "y = data.target\n",
    "\n",
    "#split into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x,y, test_size=0.2, random_state = 42\n",
    ")\n",
    "\n",
    "#initaialize catboost classifier (silent training with verbose = 0)\n",
    "model = CatBoostClassifier(iterations =200, learning_rate=0.1, depth=6, verbose=0, random_state=42)\n",
    "\n",
    "#train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#prediction \n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "#accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'CatBoost classifier Accuracy: {accuracy:.4f}')\n",
    "\n",
    "#confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#plot confusion matrix using seaborn\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot = True, fmt='d', cmap= 'Blues',\n",
    "           xticklabels=data.target_names,\n",
    "           yticklabels=data.target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('actual')\n",
    "plt.title('CatBoost Classifier - Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712658d6-af36-47f4-a48b-f49b0111a9ab",
   "metadata": {},
   "source": [
    "Question 10: You're working for a FinTech company trying to predict loan default using\n",
    "customer demographics and transaction behavior.\n",
    "The dataset is imbalanced, contains missing values, and has both numeric and\n",
    "categorical features.\n",
    "Describe your step-by-step data science pipeline using boosting techniques:\n",
    "● Data preprocessing & handling missing/categorical values\n",
    "● Choice between AdaBoost, XGBoost, or CatBoost\n",
    "● Hyperparameter tuning strategy\n",
    "● Evaluation metrics you'd choose and why\n",
    "● How the business would benefit from your model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1585de3-622c-4085-b2ae-8ab0a3201f66",
   "metadata": {},
   "source": [
    "**Step 1: Data Preprocessing**\n",
    "\n",
    "Handle Missing Values\n",
    "\n",
    "Numeric features: Impute with mean/median or use model-based imputation.\n",
    "\n",
    "Categorical features: Impute with most frequent category or use CatBoost/XGBoost’s built-in handling.\n",
    "\n",
    "**Encode Categorical Features**\n",
    "\n",
    "If using CatBoost → no manual encoding needed.\n",
    "\n",
    "If using XGBoost/AdaBoost → use one-hot encoding (for low cardinality) or target encoding (for high cardinality).\n",
    "\n",
    "Scale Numeric Features (if needed)\n",
    "\n",
    "Boosting trees don’t need scaling, but if other models are compared, apply StandardScaler/MinMaxScaler.\n",
    "\n",
    "**Handle Imbalanced Data**\n",
    "\n",
    "Use SMOTE/ADASYN (oversampling) or class weights.\n",
    "\n",
    "Alternatively, boosting libraries (like XGBoost, CatBoost) allow setting scale_pos_weight to balance classes.\n",
    "\n",
    "**Step 2: Model Choice**\n",
    "\n",
    "AdaBoost: Works but less powerful for complex, imbalanced datasets.\n",
    "\n",
    "XGBoost: Great for tabular data with many features and imbalanced classes.\n",
    "\n",
    "CatBoost: Best when categorical features are dominant, since it natively handles them.\n",
    "\n",
    "**Choice:**\n",
    "\n",
    "If categorical-heavy dataset → CatBoost.\n",
    "\n",
    "If mixed but numeric-heavy → XGBoost.\n",
    "\n",
    "**Step 3: Hyperparameter Tuning Strategy**\n",
    "\n",
    "Use GridSearchCV or RandomizedSearchCV.\n",
    "\n",
    "Key parameters to tune:\n",
    "\n",
    "n_estimators (number of trees)\n",
    "\n",
    "learning_rate (controls step size)\n",
    "\n",
    "max_depth (tree depth, prevents overfitting)\n",
    "\n",
    "subsample & colsample_bytree (for regularization)\n",
    "\n",
    "scale_pos_weight (to handle imbalance)\n",
    "\n",
    "For CatBoost, also tune:\n",
    "\n",
    "depth, iterations, l2_leaf_reg.\n",
    "\n",
    "**Step 4: Evaluation Metrics**\n",
    "\n",
    "Since the dataset is imbalanced, accuracy is misleading.\n",
    "Better metrics:\n",
    "\n",
    "ROC-AUC → overall ability to separate defaulters vs non-defaulters.\n",
    "\n",
    "Precision, Recall, F1-score → especially recall (to catch as many defaults as possible).\n",
    "\n",
    "Confusion Matrix → to analyze false negatives (missed defaults).\n",
    "\n",
    "**Step 5: Business Benefits**\n",
    "\n",
    "Reduce Financial Risk:\n",
    "\n",
    "Identify high-risk applicants → avoid defaults.\n",
    "\n",
    "Better Credit Policies:\n",
    "\n",
    "Approve more low-risk loans → increase profitability.\n",
    "\n",
    "Improved Customer Trust:\n",
    "\n",
    "Faster, fairer, and more accurate loan approval process.\n",
    "\n",
    "Regulatory Compliance:\n",
    "\n",
    "Transparent risk scoring supports compliance with financial regulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb5d083-53da-41c8-8ee8-ecffea59e15f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
